---
title: So, what is DDPM?
date: "2021-12-04"
description: "Here are visual examples of the many styles you will be able to use right out of the box with the TeXBlog starter."
ep: 1
---

## Forward Diffusion Process
$$
\text{Goal: Gradually add Gausian noise and then reverse}  
x_0 \text{\textasciitilde} q(x)\ \ \ \ \text{(original data)}
$$

$$
{\beta_t\in(0,1)}^t_{t=1} \text{ is hyperparameter}
q(x_t|x_{t-1})=\mathcal N(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_tI)
q(x_T|x_0)=\prod_{t=1}^Tq(x_t|x_{t-1})
$$
* q is markov chain
* hyperparameter를 잘 조작하면 $lim_{x\rightarrow\infin}T_x$ follows isotropic gaussian distribution

### reparameterization trick

$$
q(x_t|x_{t-1})=\mathcal N(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_tI)
 \alpha_t=1-\beta_t,\  \bar\alpha_t=\prod_{i=1}^t\alpha_i
 \;
 x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}z_{t-1} \;\;\;(z_{t-1}\text{\textasciitilde} \mathcal N(0, 1))
 = \sqrt{\alpha_t\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_t}z_{t-1} + \sqrt{\alpha_t(1-\alpha_{t-1})}z_{t-2}
 = \sqrt{\alpha_t\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}}\bar z_{t-2}\;(\text{merge two Gaussian})
 = \sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}z
$$
$$
q(x_t|x_0)=\mathcal N(x_t;\bar\alpha_t x_0, (1 - \bar\alpha_t)I)
$$

## Reverse Diffusion Process

* 역방향을 재생성할 수 있다면 좋겠지만, 현실적으로 비효율적이다. 전체 dataset을 관찰해야하기 때문이다.

$$
P_\theta(x_{0:T})=p(x_T)\prod_{t=1}^T p_\theta(x_{t-1}|x_t)
p_\theta(x_{t-1}|x_t)=\mathcal N(x_{t-1};\mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
$$
* 각 gaussian process의 mean, variance를 parametrization하여 예측한다.
* true reverse process를 알 수 없으므로 condition에 $x_0$를 추가한다. 이는 계산 가능하다.

$$
q(x_{t-1}|x_t)
q(x_t|x_{t-1})
$$
$$
q(x_{t-1}|x_t, x_0)=\mathcal N(x_{t-1};\tilde{\mu}(x_t, x_0), \tilde{\beta_t}I)
 q(x_{t-1}|x_t, x_0) = q(x_t|x_{t-1}, x_0)\frac{q(x_{t-1}| x_0)}{q(x_t| x_0)}
 \propto exp(-\frac{1}{2}(\frac{(x_t-\sqrt{\alpha_t}x_{t-1})^2}{\beta_t} + \frac{(x_{t-1}-\sqrt{\alpha_{t-1}}x_0)^2}{1-\bar\alpha_{t-1}}) - \frac{(x_t-\sqrt{\bar\alpha_t}x_0)^2}{1-\bar\alpha_t})
 = exp(
  -\frac{1}{2}
    (
      (
        \frac{\alpha_t}{\beta_t} +
        \frac{1}{1-\bar\alpha_{t-1}}
      ) x_{t-1}^2 - 
      2 (
        \frac{
            2\sqrt\alpha_t
          }{
            \beta_t
          } x_t +
        \frac{
          2\sqrt{
            \bar\alpha_t
            }
          }{
            1-\bar\alpha_{t-1}
          } x_0
      ) x_{t-1} + 
      C(x_t, x_0)
    )
  )
$$
$$
\tilde{\beta_t}
  = \frac{
    1-\bar{\alpha}_{t-1}
  } {
    1-\bar{\alpha_{t}}
  } \beta_t
\tilde{\mu}(x_t, x_0) = 
    \frac{
      1
    } {
      \sqrt{\alpha_t}
    } (
        x_t -
        \frac{
            \beta_t
          } {
            \sqrt{1-\bar\alpha_t}
          } z_t
      )
$$

* we can use VLB as our loss.
### ELBO
$$
L
= - \int q(x_0)\log{p(x_0)} dx_0
= - E_{q(x_0)}[\log{p_\theta(x_0)}]
= - E_{q(x_0)}[\log{\frac{
    p_\theta(x_{0:T})
  }{
    p_\theta(x_{1:T}|x_0)
  }}]
= - E_{q(x_0)}[\log{
    \frac{
      p_\theta(x_{0:T})
    }{
      p_\theta(x_{1:T}|x_0)
    }
    \frac{
      q_\theta(x_{1:T}|x_0)
    }{
      q_\theta(x_{1:T}|x_0)
    }
  }]
\leq - E_{q(x_0)}[\log{
    \frac{
      p_\theta(x_{0:T})
    }{
      q_\theta(x_{1:T}|x_0)
    }
  }]
]] = L_{VLB}
$$

$$
\mu_\theta(x_t, t) = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar\alpha_t}}z_\theta(x_t, t))
$$